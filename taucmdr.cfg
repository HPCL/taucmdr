# Initial default values for a new TAU Commander installation.  These can be
# changed after installation via the `tau configure` command.

# ============================================================================
# System-level application configuration defaults.
#
# New target configurations will use these values as the default if no better
# value is available.
# ============================================================================
[Application]
# application uses NVIDIA CUDA
cuda = False
# application uses MPC
mpc = False
# application uses MPI
mpi = False
# application uses OpenCL
opencl = False
# application uses OpenMP
openmp = False
# application uses pthreads
pthreads = False
# application uses SHMEM
shmem = False

# ============================================================================
# System-level measurement configuration defaults.
#
# New target configurations will use these values as the default if no better
# value is available.
# ============================================================================
[Measurement]
# maximum depth for callpath recording
callpath = 100
# record the point-to-point communication matrix
comm_matrix = False
# use compiler-generated callbacks to gather performance data
compiler_inst = never
# measure cuda events via the CUPTI interface
cuda = False
# measure heap memory usage
heap_usage = False
# measure time spent in POSIX I/O calls
io = False
# don't remove instrumented files after compilation
keep_inst_files = False
# don't instrument, only link the TAU library to the application
link_only = False
# record memory allocation and deallocation events
memory_alloc = False
# performance metrics to gather, e.g. TIME, PAPI_FP_INS
metrics = TIME,
# use MPI library wrapper to measure time spent in MPI methods
mpi = False
# measure OpenCL events
opencl = False
# use specified library to measure time spent in OpenMP directives
openmp = none
# generate application profiles
profile = tau
# reuse and preserve instrumented files after compilation
reuse_inst_files = False
# use event-based sampling to gather performance data
sample = True
# specify selective instrumentation file
select_file = 
# use hooks inserted into the application source code to gather performance
# data
source_inst = never
# throttle lightweight events to reduce overhead
throttle = True
# lightweight event call count threshold
throttle_num_calls = 100000
# lightweight event duration threshold in microseconds
throttle_per_call = 10
# generate application traces
trace = none

# ============================================================================
# System-level target configuration defaults.
#
# New target configurations will use these values as the default if no better
# value is available.
# ============================================================================
[Target]
# Host C compiler command
CC = /usr/bin/gcc
# Host C++ compiler command
CXX = /usr/bin/g++
# Host Fortran compiler command
FC = /usr/bin/gfortran
# MPI C compiler command
MPI_CC = /usr/lib64/mpi/gcc/openmpi/bin/mpicc
# MPI C++ compiler command
MPI_CXX = /usr/lib64/mpi/gcc/openmpi/bin/mpic++
# MPI Fortran compiler command
MPI_FC = /usr/lib64/mpi/gcc/openmpi/bin/mpif90
# SHMEM C compiler command
SHMEM_CC = /opt/openshmem/openshmem-release-1.0f/bin/oshcc
# SHMEM C++ compiler command
SHMEM_CXX = /opt/openshmem/openshmem-release-1.0f/bin/oshcxx
# SHMEM Fortran compiler command
SHMEM_FC = /opt/openshmem/openshmem-release-1.0f/bin/oshfort
# Universal Parallel C compiler command
UPC = 
# path or URL to a GNU binutils installation or archive file
binutils_source = download
# path to NVIDIA CUDA installation (enables OpenCL support)
cuda = 
# host architecture
host_arch = x86_64
# host operating system
host_os = Linux
# path or URL to a libunwind installation or archive file
libunwind_source = download
# paths to search for MPI header files when building MPI applications
mpi_include_path = 
# libraries to link to when building MPI applications
mpi_libraries = 
# paths to search for MPI library files when building MPI applications
mpi_library_path = 
# path or URL to a PAPI installation or archive file
papi_source = download
# path or URL to a PDT installation or archive file
pdt_source = download
# path or URL to a Score-P installation or archive file
scorep_source = download
# paths to search for SHMEM header files when building SHMEM applications
shmem_include_path = 
# libraries to link to when building SHMEM applications
shmem_libraries = 
# paths to search for SHMEM library files when building SHMEM applications
shmem_library_path = 
# path or URL to a TAU installation or archive file
tau_source = download
