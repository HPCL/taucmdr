{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to patch sys.path until we have tighter taucmdr/anaconda integration.\n",
    "# Need to move towards taucmdr as a conda package.\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    import taucmdr\n",
    "except ImportError:\n",
    "    sys.path.insert(0, os.path.join(os.environ['__TAUCMDR_HOME__'], 'packages'))\n",
    "finally:\n",
    "    from taucmdr.model.project import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = Project.selected().experiment().num_trials\n",
    "trials = Project.selected().experiment().trials(xrange(0, num_trials))\n",
    "trial_data = {}\n",
    "for i in xrange(0, num_trials):\n",
    "    trial_data[i] = trials[i].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial0_intervals = trial_data[0][0][0][0].interval_data()\n",
    "#trial0_intervals.plot(kind='bar')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent constructing dataframe of size 82878x6: 7.1334168911\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "trial_intervals = []\n",
    "for trial in xrange(0, num_trials):\n",
    "    for i in xrange(0, len(trial_data[trial])):\n",
    "        for j in xrange(0, len(trial_data[trial][i])):\n",
    "            for k in xrange(0, len(trial_data[trial][i][j])):\n",
    "                trial_intervals.append(trial_data[trial][i][j][k].interval_data())\n",
    "                #x = trial_data[trial][i][j][k].interval_data()\n",
    "                #x['percentage'] = x['Exclusive']/x.loc['.TAU application', 'Inclusive']\n",
    "                #trial_intervals.append(x)\n",
    "                \n",
    "expr_intervals = pd.concat(trial_intervals)\n",
    "end = time.time()\n",
    "print 'Time spent constructing dataframe of size %sx%s: %s' %(expr_intervals.shape[0], expr_intervals.shape[1], end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest exclusive time are: \n",
      "1: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase (144444414.0)\n",
      "2: init_phase (144444414.0)\n",
      "3: MPI_Bcast() (91653272.0)\n",
      "4: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Bcast() (91457231.0)\n",
      "5: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Recv() (56798703.0)\n",
      "6: MPI_Recv() (56798703.0)\n",
      "7: MPI_Reduce() (45090589.0)\n",
      "8: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => GCR_SOLVE::GCR_SOLVER_QSET [{gcr_solve.f90} {42,3}-{353,32}] => GCR_SOLVE_UTIL::GCR_PRECONDITIONER_QSET [{gcr_solve_util.f90} {34,3}-{80,40}] => LINEARSOLVE_NODIVCHECK::NODIVCHECK_RELAX_Q [{linearsolve_nodivcheck.F90} {35,3}-{271,35}] => POINT_SOLVER::POINT_SOLVE [{point_solver.F90} {26,3}-{225,28}] => POINT_SOLVER::POINT_SOLVE_5 [{point_solver.F90} {2612,3}-{2815,30}] (28590900.0)\n",
      "9: POINT_SOLVER::POINT_SOLVE_5 [{point_solver.F90} {2612,3}-{2815,30}] (28590900.0)\n",
      "10: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {102,3}-{119,43}] => RELAX_OPERATIONS::UPDATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {127,3}-{183,41}] => FILL_JACOBIANS::FILL_JACOBIAN [{fill_jacobians.f90} {19,3}-{142,30}] => VISCOUS_JACOBIANS::COMPUTE_INTERIOR_DRIVER [{viscous_jacobians.f90} {18,3}-{32,40}] => JACOBIAN_VISCOUS::VISCOUS_JACOBIAN [{jacobian_viscous.f90} {19,3}-{301,33}] => JACOBIAN_VISCOUS::EDGEJP_MIX_CELL_OPT [{jacobian_viscous.f90} {3503,3}-{4521,36}] (26743796.0)\n",
      "\n",
      "Time spent finding 10 most expensive regions: 0.0083179473877\n",
      "\n",
      "\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest standard deviation are: \n",
      "1: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Recv() (852453.154808)\n",
      "2: MPI_Recv() (849900.408946)\n",
      "3: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase (814918.976204)\n",
      "4: init_phase (814918.976204)\n",
      "5: MPI_Reduce() (422783.667393)\n",
      "6: JACOBIAN_VISCOUS::EDGEJP_MIX_CELL_OPT [{jacobian_viscous.f90} {3503,3}-{4521,36}] (356640.290013)\n",
      "7: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {102,3}-{119,43}] => RELAX_OPERATIONS::UPDATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {127,3}-{183,41}] => FILL_JACOBIANS::FILL_JACOBIAN [{fill_jacobians.f90} {19,3}-{142,30}] => VISCOUS_JACOBIANS::COMPUTE_INTERIOR_DRIVER [{viscous_jacobians.f90} {18,3}-{32,40}] => JACOBIAN_VISCOUS::VISCOUS_JACOBIAN [{jacobian_viscous.f90} {19,3}-{301,33}] => JACOBIAN_VISCOUS::EDGEJP_MIX_CELL_OPT [{jacobian_viscous.f90} {3503,3}-{4521,36}] (356640.290013)\n",
      "8: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => GCR_SOLVE::GCR_SOLVER_QSET [{gcr_solve.f90} {42,3}-{353,32}] => MPI_Reduce() (331653.050332)\n",
      "9: MPI_Waitall() (171636.405958)\n",
      "10: MPI_Bcast() (165865.238546)\n",
      "\n",
      "Time spent finding 10 regions with largest standard deviation: 0.0367860794067\n",
      "\n",
      "\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest correlation to total runtime are: \n",
      "1: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::UPDATE_RES_NORM_TURB [{relax_operations.f90} {448,3}-{504,37}] => MPI_Send() (1.0)\n",
      "2: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_POST [{flow.F90} {1580,3}-{1782,26}] => MPI_Recv() (0.999626036186)\n",
      "3: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_RESIDUAL [{relax_operations.f90} {63,3}-{94,43}] => MPI_Recv() (0.998999696354)\n",
      "4: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {102,3}-{119,43}] => RELAX_OPERATIONS::UPDATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {127,3}-{183,41}] => FILL_JACOBIANS::FILL_JACOBIAN [{fill_jacobians.f90} {19,3}-{142,30}] (0.998982130529)\n",
      "5: FILL_JACOBIANS::FILL_JACOBIAN [{fill_jacobians.f90} {19,3}-{142,30}] (0.998982130529)\n",
      "6: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Bcast() (0.997689038888)\n",
      "7: MPI_Bcast() (0.997677395537)\n",
      "8: RELAX_OPERATIONS::EVALUATE_TURBULENCE_JACOBIAN [{relax_operations.f90} {191,3}-{206,45}] (0.996764180876)\n",
      "9: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_TURBULENCE_JACOBIAN [{relax_operations.f90} {191,3}-{206,45}] (0.996764180876)\n",
      "10: MPI_Allgatherv() (0.996237657148)\n",
      "\n",
      "Time spent finding 10 regions with highest correlation to total runtime: 0.124716997147\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Filtering all regions with less than 5.0% of total runtime reduced number of regions from 146 to 20.\n",
      "\n",
      "Time spent filtering the dataframe: 0.190855026245\n",
      "\n",
      "\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest exclusive time are: \n",
      "1: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase (144444414.0)\n",
      "2: init_phase (144444414.0)\n",
      "3: MPI_Bcast() (91653272.0)\n",
      "4: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Bcast() (91457231.0)\n",
      "5: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Recv() (56798703.0)\n",
      "6: MPI_Recv() (56798703.0)\n",
      "7: MPI_Reduce() (45090589.0)\n",
      "8: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => GCR_SOLVE::GCR_SOLVER_QSET [{gcr_solve.f90} {42,3}-{353,32}] => GCR_SOLVE_UTIL::GCR_PRECONDITIONER_QSET [{gcr_solve_util.f90} {34,3}-{80,40}] => LINEARSOLVE_NODIVCHECK::NODIVCHECK_RELAX_Q [{linearsolve_nodivcheck.F90} {35,3}-{271,35}] => POINT_SOLVER::POINT_SOLVE [{point_solver.F90} {26,3}-{225,28}] => POINT_SOLVER::POINT_SOLVE_5 [{point_solver.F90} {2612,3}-{2815,30}] (28590900.0)\n",
      "9: POINT_SOLVER::POINT_SOLVE_5 [{point_solver.F90} {2612,3}-{2815,30}] (28590900.0)\n",
      "10: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {102,3}-{119,43}] => RELAX_OPERATIONS::UPDATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {127,3}-{183,41}] => FILL_JACOBIANS::FILL_JACOBIAN [{fill_jacobians.f90} {19,3}-{142,30}] => VISCOUS_JACOBIANS::COMPUTE_INTERIOR_DRIVER [{viscous_jacobians.f90} {18,3}-{32,40}] => JACOBIAN_VISCOUS::VISCOUS_JACOBIAN [{jacobian_viscous.f90} {19,3}-{301,33}] => JACOBIAN_VISCOUS::EDGEJP_MIX_CELL_OPT [{jacobian_viscous.f90} {3503,3}-{4521,36}] (26743796.0)\n",
      "\n",
      "Time spent finding 10 most expensive regions: 0.00336599349976\n",
      "\n",
      "\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest standard deviation are: \n",
      "1: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Recv() (852453.154808)\n",
      "2: MPI_Recv() (849900.408946)\n",
      "3: init_phase (814918.976204)\n",
      "4: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase (814918.976204)\n",
      "5: MPI_Reduce() (422783.667393)\n",
      "6: JACOBIAN_VISCOUS::EDGEJP_MIX_CELL_OPT [{jacobian_viscous.f90} {3503,3}-{4521,36}] (356640.290013)\n",
      "7: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {102,3}-{119,43}] => RELAX_OPERATIONS::UPDATE_MEANFLOW_JACOBIAN [{relax_operations.f90} {127,3}-{183,41}] => FILL_JACOBIANS::FILL_JACOBIAN [{fill_jacobians.f90} {19,3}-{142,30}] => VISCOUS_JACOBIANS::COMPUTE_INTERIOR_DRIVER [{viscous_jacobians.f90} {18,3}-{32,40}] => JACOBIAN_VISCOUS::VISCOUS_JACOBIAN [{jacobian_viscous.f90} {19,3}-{301,33}] => JACOBIAN_VISCOUS::EDGEJP_MIX_CELL_OPT [{jacobian_viscous.f90} {3503,3}-{4521,36}] (356640.290013)\n",
      "8: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => GCR_SOLVE::GCR_SOLVER_QSET [{gcr_solve.f90} {42,3}-{353,32}] => MPI_Reduce() (331653.050332)\n",
      "9: MPI_Bcast() (165865.238546)\n",
      "10: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Bcast() (165124.375697)\n",
      "\n",
      "Time spent finding 10 regions with largest standard deviation: 0.00721120834351\n",
      "\n",
      "\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest correlation to total runtime are: \n",
      "1: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => init_phase => MPI_Bcast() (0.997689038888)\n",
      "2: MPI_Bcast() (0.997677395537)\n",
      "3: RELAX_OPERATIONS::EVALUATE_TURBULENCE_JACOBIAN [{relax_operations.f90} {191,3}-{206,45}] (0.996764180876)\n",
      "4: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_TURBULENCE_JACOBIAN [{relax_operations.f90} {191,3}-{206,45}] (0.996764180876)\n",
      "5: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => RELAX_OPERATIONS::EVALUATE_MEANFLOW_RESIDUAL [{relax_operations.f90} {63,3}-{94,43}] => RES_FLOW::MEANFLOW_RESIDUAL [{res_flow.f90} {27,3}-{243,34}] => FLUX::RESIDUAL_COMPRESSIBLE [{flux.f90} {20,3}-{423,38}] (0.992975883068)\n",
      "6: FLUX::RESIDUAL_COMPRESSIBLE [{flux.f90} {20,3}-{423,38}] (0.992975883068)\n",
      "7: .TAU application (0.989157501696)\n",
      "8: .TAU application => NODET [{main.f90} {5,1}-{36,17}] => step_phase => FLOW::ITERATE [{flow.F90} {1121,3}-{1181,24}] => FLOW::STEP_SOLVER [{flow.F90} {1409,3}-{1571,28}] => RELAX_FLOW::NCFV_TIMESTEP [{relax_flow.f90} {16,3}-{119,30}] => GCR_SOLVE::GCR_SOLVER_QSET [{gcr_solve.f90} {42,3}-{353,32}] => GCR_SOLVE_UTIL::GCR_PRECONDITIONER_QSET [{gcr_solve_util.f90} {34,3}-{80,40}] => LINEARSOLVE_NODIVCHECK::NODIVCHECK_RELAX_Q [{linearsolve_nodivcheck.F90} {35,3}-{271,35}] => POINT_SOLVER::POINT_SOLVE [{point_solver.F90} {26,3}-{225,28}] => POINT_SOLVER::POINT_SOLVE_5 [{point_solver.F90} {2612,3}-{2815,30}] (0.980621320894)\n",
      "9: POINT_SOLVER::POINT_SOLVE_5 [{point_solver.F90} {2612,3}-{2815,30}] (0.980621320894)\n",
      "10: fini_phase (0.978605239017)\n",
      "\n",
      "Time spent finding 10 regions with highest correlation to total runtime: 0.04327917099\n",
      "\n",
      "\n",
      "Hotspot analysis took 0.170356988907 seconds without filtering and 0.245278120041 seconds with filtering.\n"
     ]
    }
   ],
   "source": [
    "# levels: 0=trial, 1=node, 2=context, 3=thread, 4=region name\n",
    "\n",
    "def filter_regions(dfs, percentage=0.1):\n",
    "    unstacked_dfs = dfs.unstack(4)\n",
    "    dfs['percentage'] = unstacked_dfs.loc[:,'Exclusive'].div(unstacked_dfs.loc[:,('Inclusive','.TAU application')], axis=0).stack()\n",
    "    dfs_filtered = dfs.groupby(level=4).filter(lambda x: x['percentage'].max()>percentage or x.name == '.TAU application')\n",
    "    print 'Filtering all regions with less than %s%% of total runtime reduced number of regions from %s to %s.'%(100*percentage,len(dfs.index.get_level_values(4).unique()), len(dfs_filtered.index.get_level_values(4).unique()))\n",
    "    return dfs_filtered\n",
    "\n",
    "def largest_stddev(dfs,n):\n",
    "    return dfs['Exclusive'].groupby(level=3).std(ddof=0).dropna().sort_values(ascending=False, axis=0)[:n]\n",
    "\n",
    "def largest_correlation(dfs,n):\n",
    "    unstacked_dfs = dfs.unstack(4)\n",
    "    return unstacked_dfs.loc[:,'Exclusive'].corrwith(unstacked_dfs.loc[:,('Inclusive','.TAU application')]).sort_values(ascending=False, axis=0)[:n]\n",
    "\n",
    "def largest_exclusive(dfs,n):\n",
    "    return dfs['Exclusive'].groupby(level=4).max().nlargest(n)\n",
    "\n",
    "def hotspots(dfs, n, flag):\n",
    "    if flag == 0:\n",
    "        largest = largest_exclusive(dfs,n)\n",
    "    elif flag == 1:\n",
    "        largest = largest_stddev(dfs,n)\n",
    "    elif flag == 2:\n",
    "        largest = largest_correlation(dfs,n)\n",
    "    else:\n",
    "        print 'Invalid flag'\n",
    "    y = ['exclusive time', 'standard deviation', 'correlation to total runtime']\n",
    "    print 'Hotspot Analysis Summary'\n",
    "    print '='*80\n",
    "    print 'The code regions with largest %s are: ' %y[flag]\n",
    "    for i in xrange(0,n):\n",
    "        print '%s: %s (%s)' %(i+1, largest.index[i], largest[i])\n",
    "    \n",
    "n=10\n",
    "\n",
    "# Hotspot analysis without filtering\n",
    "nofiltering_start = time.time()\n",
    "start = time.time()\n",
    "hotspots(expr_intervals, n, 0)\n",
    "end = time.time()\n",
    "print '\\nTime spent finding %s most expensive regions: %s\\n\\n' %(n, end-start)\n",
    "\n",
    "start = time.time()\n",
    "hotspots(expr_intervals.loc[0], n, 1)\n",
    "end = time.time()\n",
    "print '\\nTime spent finding %s regions with largest standard deviation: %s\\n\\n' %(n, end-start)\n",
    "\n",
    "start = time.time()\n",
    "hotspots(expr_intervals, n, 2)\n",
    "end = time.time()\n",
    "nofiltering_end = time.time()\n",
    "print '\\nTime spent finding %s regions with highest correlation to total runtime: %s\\n\\n' %(n, end-start)\n",
    "\n",
    "# Hotspot analysis with filtering\n",
    "print '='*80\n",
    "\n",
    "filtering_start = time.time()\n",
    "start = time.time()\n",
    "filtered_dfs = filter_regions(expr_intervals, 0.05)\n",
    "end = time.time()\n",
    "print '\\nTime spent filtering the dataframe: %s\\n\\n' %(end-start)\n",
    "filtered_dfs\n",
    "\n",
    "start = time.time()\n",
    "hotspots(filtered_dfs, n, 0)\n",
    "end = time.time()\n",
    "print '\\nTime spent finding %s most expensive regions: %s\\n\\n' %(n, end-start)\n",
    "\n",
    "start = time.time()\n",
    "hotspots(filtered_dfs.loc[0], n, 1)\n",
    "end = time.time()\n",
    "print '\\nTime spent finding %s regions with largest standard deviation: %s\\n\\n' %(n, end-start)\n",
    "\n",
    "start = time.time()\n",
    "hotspots(filtered_dfs, n, 2)\n",
    "end = time.time()\n",
    "filtering_end = time.time()\n",
    "print '\\nTime spent finding %s regions with highest correlation to total runtime: %s\\n\\n' %(n, end-start)\n",
    "\n",
    "print 'Hotspot analysis took %s seconds without filtering and %s seconds with filtering.' %(nofiltering_end-nofiltering_start, filtering_end-filtering_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
