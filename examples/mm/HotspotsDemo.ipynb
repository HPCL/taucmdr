{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to patch sys.path until we have tighter taucmdr/anaconda integration.\n",
    "# Need to move towards taucmdr as a conda package.\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    import taucmdr\n",
    "except ImportError:\n",
    "    sys.path.insert(0, os.path.join(os.environ['__TAUCMDR_HOME__'], 'packages'))\n",
    "finally:\n",
    "    from taucmdr.model.project import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = Project.selected().experiment().num_trials\n",
    "trials = Project.selected().experiment().trials(xrange(0, num_trials))\n",
    "trial_data = {}\n",
    "for i in xrange(0, num_trials):\n",
    "    trial_data[i] = trials[i].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial0_intervals = trial0_data[0][0][0].interval_data()\n",
    "#trial0_intervals.plot(kind='bar')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_intervals = {}\n",
    "for trial in xrange(0, num_trials):\n",
    "    trial_intervals[trial] = {}\n",
    "    for i in xrange(0, len(trial_data[trial])):\n",
    "        trial_intervals[trial][i] = {}\n",
    "        for j in xrange(0, len(trial_data[trial][i])):\n",
    "            trial_intervals[trial][i][j] = {}\n",
    "            for k in xrange(0, len(trial_data[trial][i][j])):\n",
    "                trial_intervals[trial][i][j][k] = trial_data[trial][i][j][k].interval_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest exclusive time are: \n",
      "1: void compute(double **, double **, double **, int, int, int) C [{matmult.c} {90,1}-{109,1}]  \n",
      "2: .TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => void compute(double **, double **, double **, int, int, int) C [{matmult.c} {90,1}-{109,1}]  \n",
      "3: .TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => void compute_interchange(double **, double **, double **, int, int, int) C [{matmult.c} {111,1}-{130,1}]  \n",
      "4: void compute_interchange(double **, double **, double **, int, int, int) C [{matmult.c} {111,1}-{130,1}]  \n",
      "5: double multiply(double, double) C [{matmult.c} {59,1}-{61,1}] [THROTTLED]\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest standard deviation are: \n",
      "1: ('.TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => double **allocateMatrix(int, int) C [{matmult.c} {42,1}-{49,1}]  ', 0.0)\n",
      "2: ('double multiply(double, double) C [{matmult.c} {59,1}-{61,1}] [THROTTLED]', 0.0)\n",
      "3: ('void compute(double **, double **, double **, int, int, int) C [{matmult.c} {90,1}-{109,1}]  ', 0.0)\n",
      "4: ('.TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => void initialize(double **, int, int) C [{matmult_initialize.c} {3,1}-{16,1}]  ', 0.0)\n",
      "5: ('.TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => void compute_interchange(double **, double **, double **, int, int, int) C [{matmult.c} {111,1}-{130,1}]  ', 0.0)\n",
      "Hotspot Analysis Summary\n",
      "================================================================================\n",
      "The code regions with largest correlation to total runtime are: \n",
      "1: ('void compute(double **, double **, double **, int, int, int) C [{matmult.c} {90,1}-{109,1}]  ', 0.96282627275589139)\n",
      "2: ('.TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => void compute(double **, double **, double **, int, int, int) C [{matmult.c} {90,1}-{109,1}]  ', 0.96282627275589139)\n",
      "3: ('.TAU application => int main(int, char **) C [{matmult.c} {209,1}-{299,1}]   => double do_work(void) C [{matmult.c} {132,1}-{168,1}]   => void initialize(double **, int, int) C [{matmult_initialize.c} {3,1}-{16,1}]  ', 0.85882887359614413)\n",
      "4: ('void initialize(double **, int, int) C [{matmult_initialize.c} {3,1}-{16,1}]  ', 0.85882887359614413)\n",
      "5: ('void compute_interchange(double **, double **, double **, int, int, int) C [{matmult.c} {111,1}-{130,1}]  ', 0.85240994831002848)\n"
     ]
    }
   ],
   "source": [
    "from taucmdr.error import InternalError\n",
    "def get_dfs_depth(dfs, level=1):\n",
    "    depth = 0\n",
    "    if not isinstance(dfs, dict) or not dfs:\n",
    "        return level\n",
    "    return max(get_dfs_depth(dfs[k], level + 1) for k in dfs)\n",
    "\n",
    "def get_regions(dfs):\n",
    "    regions = set()\n",
    "    depth = get_dfs_depth(dfs)\n",
    "    \n",
    "    # Contains profile data for 1 thread\n",
    "    if depth == 1:\n",
    "        regions.update(dfs.index.tolist())\n",
    "    # Contains profile data for 1 trial with multiple threads\n",
    "    elif depth == 4:\n",
    "        for rank in dfs:\n",
    "            for context in dfs[rank]:\n",
    "                for thread in dfs[rank][context]:\n",
    "                    regions.update(dfs[rank][context][thread].index.tolist())\n",
    "    # Contains profile data for an experiment with multiple trials\n",
    "    elif depth == 5:\n",
    "        for tr in dfs:\n",
    "            for rank in dfs[tr]:\n",
    "                for context in dfs[tr][rank]:\n",
    "                    for thread in dfs[tr][rank][context]:\n",
    "                        regions.update(dfs[tr][rank][context][thread].index.tolist())\n",
    "    # Otherwise, not data is not valid\n",
    "    else:\n",
    "        raise InternalError('Invalid experiment data')\n",
    "    return regions\n",
    "\n",
    "def largest_stddev(dfs,n):\n",
    "    # Use Welford's Method (see https://stackoverflow.com/questions/895929/how-do-i-determine-the-standard-deviation-stddev-of-a-set-of-values)\n",
    "    if get_dfs_depth(dfs) != 4:\n",
    "        raise InternalError('Invalid experiment data. Must pass 1 trial only.')\n",
    "    regions = get_regions(dfs)\n",
    "    stddevs = {}\n",
    "    for region in regions:\n",
    "        mean = 0.0\n",
    "        stddev = 0.0\n",
    "        k = 1\n",
    "        for rank in dfs:\n",
    "            for context in dfs[rank]:\n",
    "                for thread in dfs[rank][context]:\n",
    "                    try:\n",
    "                        exclusive_time = dfs[rank][context][thread].at[region, 'Exclusive']\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    else:\n",
    "                        tmpM = mean\n",
    "                        mean += (exclusive_time - tmpM) / k\n",
    "                        stddev += (exclusive_time - tmpM) * (exclusive_time - mean)\n",
    "                        k += 1\n",
    "\n",
    "        stddev = math.sqrt(stddev/(k-1))\n",
    "        stddevs[region] = stddev\n",
    "\n",
    "        \n",
    "    return [x for x in sorted(stddevs.iteritems(), key=operator.itemgetter(1), reverse=True)[:n]]\n",
    "\n",
    "\n",
    "def largest_correlation(dfs,n):\n",
    "    if get_dfs_depth(dfs) != 5:\n",
    "        raise InternalError('Invalid experiment data. Must pass multiple trials.')\n",
    "    regions = get_regions(dfs)\n",
    "    regions.remove('.TAU application')\n",
    "    regions_dict = {}\n",
    "    for region in regions:\n",
    "        regions_dict[region] = []\n",
    "        for tr in dfs:\n",
    "            for rank in dfs[tr]:\n",
    "                for context in dfs[tr][rank]:\n",
    "                    for thread in dfs[tr][rank][context]:\n",
    "                        try:\n",
    "                            regions_dict[region].append(dfs[tr][rank][context][thread].at[region, 'Exclusive'])\n",
    "                        except:\n",
    "                            regions_dict[region].append(0)\n",
    "    regions_dict['.TAU application'] = []\n",
    "    for tr in dfs:\n",
    "        for rank in dfs[tr]:\n",
    "            for context in dfs[tr][rank]:\n",
    "                for thread in dfs[tr][rank][context]:\n",
    "                    regions_dict['.TAU application'].append(dfs[tr][rank][context][thread].at['.TAU application', 'Inclusive'])\n",
    "\n",
    "    corr_coef = {}\n",
    "    for region in regions:\n",
    "        corr_coef[region] = np.corrcoef(regions_dict[region], regions_dict['.TAU application'])[0,1]\n",
    "    \n",
    "\n",
    "    return [x for x in sorted(corr_coef.iteritems(), key=operator.itemgetter(1), reverse=True)[:n]]\n",
    "\n",
    "def largest_exclusive(df,n):\n",
    "    rows = df.nlargest(n, 'Exclusive')\n",
    "    return list(rows.index)\n",
    "\n",
    "def hotspots(dfs, n, flag):\n",
    "    if flag == 0:\n",
    "        largest = largest_exclusive(dfs,n)\n",
    "    elif flag == 1:\n",
    "        largest = largest_stddev(dfs,n)\n",
    "    elif flag == 2:\n",
    "        largest = largest_correlation(dfs,n)\n",
    "    else:\n",
    "        print 'Invalid flag'\n",
    "    y = ['exclusive time', 'standard deviation', 'correlation to total runtime']\n",
    "    print 'Hotspot Analysis Summary'\n",
    "    print '='*80\n",
    "    print 'The code regions with largest %s are: ' %y[flag]\n",
    "    for i in xrange(0,n):\n",
    "        print '%s: %s' %(i+1, largest[i])\n",
    "\n",
    "hotspots(trial_intervals[0][0][0][0], 5, 0)\n",
    "hotspots(trial_intervals[0], 5, 1)\n",
    "hotspots(trial_intervals, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
